<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>store_files</name>
    <description/>
    <extended_description>***** BEGIN LICENSE BLOCK *****
Version: MPL 1.1&#47;GPL 2.0&#47;LGPL 2.1

The contents of this file are subject to the Mozilla Public License Version
1.1 (the &quot;License&quot;); you may not use this file except in compliance with
the License. You may obtain a copy of the License at
http:&#47;&#47;www.mozilla.org&#47;MPL&#47;

Software distributed under the License is distributed on an &quot;AS IS&quot; basis,
WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
for the specific language governing rights and limitations under the
License.

The Original Code is Mozilla Corporation Metrics ETL for Mango

The Initial Developer of the Original Code is
Daniel Einspanjer deinspanjer@mozilla.com
Portions created by the Initial Developer are Copyright (C) 2011
the Initial Developer. All Rights Reserved.

Contributor(s):

Alternatively, the contents of this file may be used under the terms of
either the GNU General Public License Version 2 or later (the &quot;GPL&quot;), or
the GNU Lesser General Public License Version 2.1 or later (the &quot;LGPL&quot;),
in which case the provisions of the GPL or the LGPL are applicable instead
of those above. If you wish to allow use of your version of this file only
under the terms of either the GPL or the LGPL, and not to allow others to
use your version of this file under the terms of the MPL, indicate your
decision by deleting the provisions above and replace them with the notice
and other provisions required by the LGPL or the GPL. If you do not delete
the provisions above, a recipient may use your version of this file under
the terms of any one of the MPL, the GPL or the LGPL.

***** END LICENSE BLOCK *****
</extended_description>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>&#47;</directory>
    <parameters>
        <parameter>
            <name>MAXMIND_GEOIPCITY_DB</name>
            <default_value>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPCityNew.dat</default_value>
            <description/>
        </parameter>
        <parameter>
            <name>MAXMIND_GEOIPDOMAIN_DB</name>
            <default_value>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPDomain.dat</default_value>
            <description/>
        </parameter>
        <parameter>
            <name>MAXMIND_GEOIPISP_DB</name>
            <default_value>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPISP.dat</default_value>
            <description/>
        </parameter>
        <parameter>
            <name>MAXMIND_GEOIPORG_DB</name>
            <default_value>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPOrg.dat</default_value>
            <description/>
        </parameter>
    </parameters>
    <log>
<trans-log-table><connection/>
<schema/>
<table/>
<size_limit_lines/>
<interval/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject/></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject/></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject/></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject/></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject/></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject/></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field></trans-log-table>
<perf-log-table><connection/>
<schema/>
<table/>
<interval/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
<channel-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<step-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
        <partitionschema>
          <name>by_hour</name>
          <partition>            <id>primary_hour</id>
          </partition>          <partition>            <id>secondary_hour</id>
          </partition>          <dynamic>N</dynamic>
          <partitions_per_slave>2</partitions_per_slave>
        </partitionschema>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
  <created_user>-</created_user>
  <created_date>2011&#47;04&#47;03 17:45:00.096</created_date>
  <modified_user>-</modified_user>
  <modified_date>2011&#47;04&#47;03 17:45:00.096</modified_date>
  </info>
  <notepads>
  </notepads>
  <order>
  <hop> <from>GZIP CSV Input</from><to>Join metadata</to><enabled>Y</enabled> </hop>  <hop> <from>GeoIP City</from><to>GeoIP Org</to><enabled>Y</enabled> </hop>  <hop> <from>GeoIP Domain</from><to>GeoIP ISP</to><enabled>Y</enabled> </hop>  <hop> <from>GeoIP Org</from><to>GeoIP Domain</to><enabled>Y</enabled> </hop>  <hop> <from>Filter failures</from><to>Select values</to><enabled>Y</enabled> </hop>  <hop> <from>GeoIP ISP</from><to>Parse UA</to><enabled>Y</enabled> </hop>  <hop> <from>Date Parse</from><to>Write Non-Anonymized</to><enabled>Y</enabled> </hop>  <hop> <from>Date Parse</from><to>Write Anonymized</to><enabled>Y</enabled> </hop>  <hop> <from>Flag Blacklisted</from><to>GeoIP City</to><enabled>Y</enabled> </hop>  <hop> <from>Select values</from><to>Flag Blacklisted</to><enabled>Y</enabled> </hop>  <hop> <from>Date Parse</from><to>Write Non-Anonymized (No lzo&#47;hadoop)</to><enabled>N</enabled> </hop>  <hop> <from>Date Parse</from><to>Write Anonymized (No lzo&#47;hadoop)</to><enabled>N</enabled> </hop>  <hop> <from>Parse UA</from><to>Date Parse</to><enabled>Y</enabled> </hop>  <hop> <from>Line parse trans</from><to>Filter failures</to><enabled>Y</enabled> </hop>  <hop> <from>Join metadata</from><to>Line parse trans</to><enabled>Y</enabled> </hop>  <hop> <from>Get Variables</from><to>Join Rows (cartesian product)</to><enabled>Y</enabled> </hop>  <hop> <from>Get files metadata</from><to>Join Rows (cartesian product)</to><enabled>Y</enabled> </hop>  <hop> <from>Data Grid</from><to>Join Rows (cartesian product)</to><enabled>N</enabled> </hop>  <hop> <from>Join Rows (cartesian product)</from><to>GZIP CSV Input</to><enabled>Y</enabled> </hop>  <hop> <from>Join Rows (cartesian product)</from><to>Join metadata</to><enabled>Y</enabled> </hop>  </order>
  <step>
    <name>Data Grid</name>
    <type>DataGrid</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>filename</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
      </field>
      <field>
        <name>common_path</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
      </field>
      <field>
        <name>short_filename</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
      </field>
      <field>
        <name>site_name</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
      </field>
      <field>
        <name>log_parser</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
      </field>
    </fields>
    <data>
      <line> <item>&#47;home&#47;tgf&#47;theOtherWorkspace&#47;logs&#47;download.mozilla.org.access_2011-06-01-11.gz</item><item>pm-zlb-amo02.nms.mozilla.org</item><item>download.mozilla.org.access_2011-06-01-11.gz</item><item>download.mozilla.org</item><item>default</item> </line>
    </data>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>204</xloc>
      <yloc>46</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Date Parse</name>
    <type>UserDefinedJavaClass</type>
    <description/>
    <distribute>N</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>

    <definitions>
        <definition>
        <class_type>TRANSFORM_CLASS</class_type>

        <class_name>RowProcessor</class_name>

        <class_source><![CDATA[import java.util.*;
import java.util.concurrent.ConcurrentHashMap;

private static String FIELD_NAME = "request_timestamp";

private static final Map timeZones = new ConcurrentHashMap();
private static final Map months;
static
{
    Map tmp = new HashMap();
    tmp.put("Jan", new Integer(0));
    tmp.put("Feb", new Integer(1));
    tmp.put("Mar", new Integer(2));
    tmp.put("Apr", new Integer(3));
    tmp.put("May", new Integer(4));
    tmp.put("Jun", new Integer(5));
    tmp.put("Jul", new Integer(6));
    tmp.put("Aug", new Integer(7));
    tmp.put("Sep", new Integer(8));
    tmp.put("Oct", new Integer(9));
    tmp.put("Nov", new Integer(10));
    tmp.put("Dec", new Integer(11));
    months = Collections.unmodifiableMap(tmp);
}

private final Calendar calIn = Calendar.getInstance();
private final Calendar calOut = Calendar.getInstance();
private TimeZone serverTimeZone;
private TimeZone gmtTimeZone;
private String lastServerTimeZoneString;

private ValueMetaInterface inFieldMeta;
private int inFieldIndex;

private int timezoneIdx, utcDateIdx, utcHourIdx, utcTimestampIdx, clientTimestampIdx;

private int outputRowSize;

public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException
{

	Object[] r = getRow();
	if (r == null) {
		setOutputDone();
		return false;
	}

  if (first)
  {
	  first = false;
		data.inputRowMeta = getInputRowMeta();
	    data.outputRowMeta = data.inputRowMeta.clone();
		meta.getFields(data.outputRowMeta, getStepname(), null, null, parent);
		outputRowSize = data.outputRowMeta.size();
		gmtTimeZone = TimeZone.getTimeZone("GMT");
		calIn.clear(Calendar.MILLISECOND);

		inFieldIndex = data.inputRowMeta.indexOfValue(FIELD_NAME);
		inFieldMeta = data.inputRowMeta.searchValueMeta(FIELD_NAME);
		timezoneIdx = data.inputRowMeta.indexOfValue("geoip_timezone");
		//output rows
		//  		utcDateIdx, utcHourIdx, utcTimestampIdx, clientTimestampIdx;
		utcDateIdx = data.outputRowMeta.indexOfValue("utc_date");
		utcHourIdx = data.outputRowMeta.indexOfValue("utc_hour");
		utcTimestampIdx = data.outputRowMeta.indexOfValue("utc_timestamp");
		clientTimestampIdx = data.outputRowMeta.indexOfValue("client_timestamp");
  }

  Object[] outputRow = RowDataUtil.resizeArray(r, outputRowSize);
  String date =  inFieldMeta.getString(r[inFieldIndex]);
  //String date =  r[inFieldIndex]; //get(Fields.In, "request_timestamp").getString(r);

  int dom = Integer.parseInt(date.substring(0, 2));
  int month = ((Integer)months.get(date.substring(3, 6))).intValue();
  int year = Integer.parseInt(date.substring(7, 11));
  int hour = Integer.parseInt(date.substring(12, 14));
  int minute = Integer.parseInt(date.substring(15, 17));
  int second = Integer.parseInt(date.substring(18, 20));

  String tzs = date.substring(21, 26);
  if (!tzs.equals(lastServerTimeZoneString)) {
	lastServerTimeZoneString = tzs;
	  serverTimeZone = (TimeZone)timeZones.get(tzs);
		if (serverTimeZone == null) {
     	serverTimeZone = TimeZone.getTimeZone("GMT"+tzs);
     	timeZones.put(tzs, serverTimeZone);
		}
  }

  calIn.setTimeZone(serverTimeZone);
  calIn.set(year, month, dom, hour, minute, second);
  calOut.setTimeZone(gmtTimeZone);
  calOut.setTime(calIn.getTime());

  Long domParse = Long.valueOf(calOut.get(Calendar.DAY_OF_MONTH));
  Long monthParse = Long.valueOf(calOut.get(Calendar.MONTH)+1);
  Long yearParse = Long.valueOf(calOut.get(Calendar.YEAR));
	Long hourParse = Long.valueOf(calOut.get(Calendar.HOUR_OF_DAY));
	Long minuteParse = Long.valueOf(calOut.get(Calendar.MINUTE));
	Long secondParse = Long.valueOf(calOut.get(Calendar.SECOND));

	String dateString = String.format("%d-%02d-%02d", new Object[] { yearParse, monthParse, domParse });
	String utcTimestamp = String.format("%sT%02d:%02d:%02dZ", new Object[] { dateString, hourParse, minuteParse, secondParse });

	outputRow[utcDateIdx] = dateString;
	outputRow[utcHourIdx] = hourParse;
	outputRow[utcTimestampIdx] = utcTimestamp;

//	get(Fields.Out, "utc_date").setValue(outputRow, dateString);
//	get(Fields.Out, "utc_hour").setValue(outputRow, hourParse);
//	get(Fields.Out, "utc_timestamp").setValue(outputRow, utcTimestamp);
//TODO: PDI-4981
	tzs = (String) outputRow[timezoneIdx]; // get(Fields.In, "geoip_timezone").getString(r);


	if ("??".equals(tzs)) {
		outputRow[clientTimestampIdx] = utcTimestamp.replace("Z", "-00:00");
		// get(Fields.Out, "client_timestamp").setValue(outputRow, utcTimestamp.replace("Z", "-00:00"));
	} else {
		TimeZone timeZone = (TimeZone)timeZones.get(tzs);
		if (timeZone == null) {
			   	timeZone = TimeZone.getTimeZone(tzs);
			   	timeZones.put(tzs, timeZone);
		}
		calOut.setTimeZone(timeZone);
		calOut.setTime(calIn.getTime());
		outputRow[clientTimestampIdx] = javax.xml.bind.DatatypeConverter.printDateTime(calOut);

	//	get(Fields.Out, "client_timestamp").setValue(outputRow, 
	//		javax.xml.bind.DatatypeConverter.printDateTime(calOut));
	}

  	putRow(data.outputRowMeta, outputRow);
	return true;


}]]></class_source>
        </definition>
    </definitions>
    <fields>
        <field>
        <field_name>utc_date</field_name>

        <field_type>String</field_type>

        <field_length>10</field_length>

        <field_precision>-1</field_precision>

        </field>
        <field>
        <field_name>utc_hour</field_name>

        <field_type>Integer</field_type>

        <field_length>2</field_length>

        <field_precision>0</field_precision>

        </field>
        <field>
        <field_name>utc_timestamp</field_name>

        <field_type>String</field_type>

        <field_length>20</field_length>

        <field_precision>-1</field_precision>

        </field>
        <field>
        <field_name>client_timestamp</field_name>

        <field_type>String</field_type>

        <field_length>25</field_length>

        <field_precision>-1</field_precision>

        </field>
    </fields><clear_result_fields>N</clear_result_fields>
<info_steps></info_steps><target_steps></target_steps><usage_parameters></usage_parameters>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>750</xloc>
      <yloc>251</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Filter failures</name>
    <type>JavaFilter</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
<send_true_to/>
<send_false_to/>
<condition>parse_result</condition>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>333</xloc>
      <yloc>368</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Flag Blacklisted</name>
    <type>IPBlacklistValidation</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
	<ipField>ip</ipField>
	<blacklistFilePath>${BLACKLIST_FILE_LOCATION}</blacklistFilePath>
	<outputField>not_in_blacklist</outputField>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>334</xloc>
      <yloc>119</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Format runtime</name>
    <type>SelectValues</type>
    <description/>
    <distribute>N</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>        <select_unspecified>N</select_unspecified>
      <meta>        <name>runtime</name>
        <rename>runtime</rename>
        <type>String</type>
        <length>12</length>
        <precision>-2</precision>
        <conversion_mask>yyyyMMddHHmmss</conversion_mask>
        <date_format_lenient>false</date_format_lenient>
        <encoding/>
        <decimal_symbol/>
        <grouping_symbol/>
        <currency_symbol/>
        <storage_type/>
      </meta>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>391</xloc>
      <yloc>758</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>GZIP CSV Input</name>
    <type>ParallelGzipCsvInput</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <filename/>
    <filename_field>filename</filename_field>
    <rownum_field>linenum</rownum_field>
    <include_filename>Y</include_filename>
    <separator>	</separator>
    <enclosure/>
    <header>N</header>
    <buffer_size>50000</buffer_size>
    <lazy_conversion>N</lazy_conversion>
    <add_filename_result>N</add_filename_result>
    <parallel>N</parallel>
    <encoding/>
    <fields>
      <field>
        <name>line</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>200</xloc>
      <yloc>150</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>GeoIP City</name>
    <type>MaxMindGeoIPLookup</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
   <ip_address_field_name>ip</ip_address_field_name>
   <db_location>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPCity.dat</db_location>
   <db_type>CITY</db_type>
    <fields>      <field>        <name>country_code</name>
        <lookup_type>country_code</lookup_type>
        <ifnull>??</ifnull>
      </field>      <field>        <name>geoip_timezone</name>
        <lookup_type>timezone</lookup_type>
        <ifnull>0000</ifnull>
      </field>      <field>        <name>geohash</name>
        <lookup_type>geohash</lookup_type>
        <ifnull>??</ifnull>
      </field>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>494</xloc>
      <yloc>119</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>GeoIP Domain</name>
    <type>MaxMindGeoIPLookup</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
   <ip_address_field_name>ip</ip_address_field_name>
   <db_location>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPDomain.dat</db_location>
   <db_type>DOMAIN</db_type>
    <fields>      <field>        <name>domain</name>
        <lookup_type>domain_name</lookup_type>
        <ifnull>??</ifnull>
      </field>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>498</xloc>
      <yloc>316</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>GeoIP ISP</name>
    <type>MaxMindGeoIPLookup</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
   <ip_address_field_name>ip</ip_address_field_name>
   <db_location>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPISP.dat</db_location>
   <db_type>ISP</db_type>
    <fields>      <field>        <name>isp</name>
        <lookup_type>isp_name</lookup_type>
        <ifnull>??</ifnull>
      </field>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>498</xloc>
      <yloc>416</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>GeoIP Org</name>
    <type>MaxMindGeoIPLookup</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
   <ip_address_field_name>ip</ip_address_field_name>
   <db_location>&#47;usr&#47;local&#47;share&#47;GeoIP&#47;GeoIPOrg.dat</db_location>
   <db_type>ORG</db_type>
    <fields>      <field>        <name>org</name>
        <lookup_type>organization_name</lookup_type>
        <ifnull>??</ifnull>
      </field>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>498</xloc>
      <yloc>216</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get Variables</name>
    <type>GetVariable</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>runtime</name>
        <variable>${RUNTIME}</variable>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>14</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>73</xloc>
      <yloc>379</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get files metadata</name>
    <type>RowsFromResult</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>      <field>        <name>filename</name>
        <type>String</type>
        <length>500</length>
        <precision>-1</precision>
        </field>      <field>        <name>common_path</name>
        <type>String</type>
        <length>500</length>
        <precision>-1</precision>
        </field>      <field>        <name>short_filename</name>
        <type>String</type>
        <length>500</length>
        <precision>-1</precision>
        </field>      <field>        <name>site_name</name>
        <type>String</type>
        <length>50</length>
        <precision>-1</precision>
        </field>      <field>        <name>log_parser</name>
        <type>String</type>
        <length>50</length>
        <precision>-1</precision>
        </field>      </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>72</xloc>
      <yloc>128</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get runtime</name>
    <type>SystemInfo</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>runtime</name>
        <type>system date (fixed)</type>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>234</xloc>
      <yloc>718</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Join Rows (cartesian product)</name>
    <type>JoinRows</type>
    <description/>
    <distribute>N</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
      <directory>%%java.io.tmpdir%%</directory>
      <prefix>out</prefix>
      <cache_size>500</cache_size>
      <main/>
    <compare>
<condition>
 <negated>N</negated>
 <leftvalue/>
 <function>=</function>
 <rightvalue/>
 </condition>
    </compare>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>70</xloc>
      <yloc>258</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Join metadata</name>
    <type>StreamLookup</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <from>Join Rows (cartesian product)</from>
    <input_sorted>N</input_sorted>
    <preserve_memory>N</preserve_memory>
    <sorted_list>Y</sorted_list>
    <integer_pair>N</integer_pair>
    <lookup>
      <key>
        <name>filename</name>
        <field>filename</field>
      </key>
      <value>
        <name>site_name</name>
        <rename>site_name</rename>
        <default/>
        <type>String</type>
      </value>
      <value>
        <name>runtime</name>
        <rename>runtime</rename>
        <default/>
        <type>String</type>
      </value>
      <value>
        <name>common_path</name>
        <rename>common_path</rename>
        <default/>
        <type>String</type>
      </value>
      <value>
        <name>short_filename</name>
        <rename>short_filename</rename>
        <default/>
        <type>String</type>
      </value>
    </lookup>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>199</xloc>
      <yloc>259</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Line parse trans</name>
    <type>Mapping</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <specification_method>filename</specification_method>
    <trans_object_id/>
    <trans_name/>
    <filename>${Internal.Transformation.Filename.Directory}\${PARSER_TYPE}_parse_trans.ktr</filename>
    <directory_path/>
    <mappings>
      <input>
    <mapping>    <input_step>Join metadata</input_step>
    <output_step>Mapping input specification</output_step>
    <main_path>Y</main_path>
    <rename_on_output>N</rename_on_output>
    <description/>
    </mapping>      </input>
      <output>
    <mapping>    <input_step>Mapping output specification</input_step>
    <output_step>Filter failures</output_step>
    <main_path>Y</main_path>
    <rename_on_output>N</rename_on_output>
    <description/>
    </mapping>      </output>
          <parameters>    <inherit_all_vars>Y</inherit_all_vars>
    </parameters>
    </mappings>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>202</xloc>
      <yloc>371</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Parse UA</name>
    <type>Mapping</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <specification_method>filename</specification_method>
    <trans_object_id/>
    <trans_name/>
    <filename>${Internal.Transformation.Filename.Directory}&#47;process_user_agent_string.4.1.ktr</filename>
    <directory_path/>
    <mappings>
      <input>
    <mapping>    <input_step/>
    <output_step/>
    <main_path>Y</main_path>
    <rename_on_output>N</rename_on_output>
    <description/>
    </mapping>      </input>
      <output>
    <mapping>    <input_step/>
    <output_step/>
    <main_path>Y</main_path>
    <rename_on_output>N</rename_on_output>
    <description/>
       <connector><parent>locale</parent><child>user_agent_locale</child></connector>
    </mapping>      </output>
          <parameters>    <inherit_all_vars>Y</inherit_all_vars>
    </parameters>
    </mappings>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>654</xloc>
      <yloc>111</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Select values</name>
    <type>SelectValues</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>      <field>        <name>site_name</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>runtime</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>common_path</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>short_filename</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>linenum</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>ip</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>auth</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>ident</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>request_timestamp</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>request_method</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>request_uri</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>request_version</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>response_code</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>response_size</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>referrer</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>user_agent</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>      <field>        <name>cookies</name>
        <rename/>
        <length>-2</length>
        <precision>-2</precision>
      </field>        <select_unspecified>N</select_unspecified>
    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>334</xloc>
      <yloc>239</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Write Anonymized</name>
    <type>UserDefinedJavaClass</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>

    <definitions>
        <definition>
        <class_type>TRANSFORM_CLASS</class_type>

        <class_name>Processor</class_name>

        <class_source><![CDATA[import java.util.*;
import java.io.IOException;
import java.io.BufferedWriter;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import org.apache.commons.vfs.FileObject;
import org.pentaho.di.core.vfs.KettleVFS;

import org.apache.hadoop.conf.Configuration;
import com.hadoop.compression.lzo.LzopCodec;
import org.apache.hadoop.io.compress.CompressionOutputStream;

private LzopCodec lzoCodec;
private Configuration config;

private HashMap writers = new HashMap();

private static final String BLACKLIST_FLAG="\tblacklisted";

int site_nameIdx, utc_dateIdx, utc_hourIdx, runtimeIdx, not_in_blacklistIdx,
    common_pathIdx, short_filenameIdx, linenumIdx, utc_timestampIdx, client_timestampIdx,
    country_codeIdx, geohashIdx, domainIdx, orgIdx, ispIdx,
    request_methodIdx, request_uriIdx, request_versionIdx, response_codeIdx, response_sizeIdx,
    referrerIdx, browser_categoryIdx, browser_nameIdx, browser_versionIdx, user_agent_localeIdx,
    platformIdx, os_categoryIdx, osIdx;


public boolean init(StepMetaInterface stepMetaInterface, StepDataInterface stepDataInterface)
{
	config = new Configuration();
	config.set("fs.default.name", getParameter("HDFS_LOCATION"));
    lzoCodec = new LzopCodec();
	lzoCodec.setConf(config);
	data.inputRowMeta.clear();
	data.inputRowMeta = null;
    return parent.initImpl(stepMetaInterface, stepDataInterface);
}

public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException
{
	Object[] r = getRow();
	if (r == null) {
		setOutputDone();
		return false;
	}

    try {
        if (first)
        {
            first = false;
			data.inputRowMeta = getInputRowMeta();

// TODO PDI-4981
            site_nameIdx = data.inputRowMeta.indexOfValue("site_name");
            utc_dateIdx = data.inputRowMeta.indexOfValue("utc_date");
            utc_hourIdx = data.inputRowMeta.indexOfValue("utc_hour");
            runtimeIdx = data.inputRowMeta.indexOfValue("runtime");
            not_in_blacklistIdx = data.inputRowMeta.indexOfValue("not_in_blacklist");
            common_pathIdx = data.inputRowMeta.indexOfValue("common_path");
            short_filenameIdx = data.inputRowMeta.indexOfValue("short_filename");
            linenumIdx = data.inputRowMeta.indexOfValue("linenum");
            utc_timestampIdx = data.inputRowMeta.indexOfValue("utc_timestamp");
            client_timestampIdx = data.inputRowMeta.indexOfValue("client_timestamp");
            country_codeIdx = data.inputRowMeta.indexOfValue("country_code");
            geohashIdx = data.inputRowMeta.indexOfValue("geohash");
            domainIdx = data.inputRowMeta.indexOfValue("domain");
            orgIdx = data.inputRowMeta.indexOfValue("org");
            ispIdx = data.inputRowMeta.indexOfValue("isp");
            request_methodIdx = data.inputRowMeta.indexOfValue("request_method");
            request_uriIdx = data.inputRowMeta.indexOfValue("request_uri");
            request_versionIdx = data.inputRowMeta.indexOfValue("request_version");
            response_codeIdx = data.inputRowMeta.indexOfValue("response_code");
            response_sizeIdx = data.inputRowMeta.indexOfValue("response_size");
            referrerIdx = data.inputRowMeta.indexOfValue("referrer");
            browser_categoryIdx = data.inputRowMeta.indexOfValue("browser_category");
            browser_nameIdx = data.inputRowMeta.indexOfValue("browser_name");
            browser_versionIdx = data.inputRowMeta.indexOfValue("browser_version");
            user_agent_localeIdx = data.inputRowMeta.indexOfValue("user_agent_locale");
            platformIdx = data.inputRowMeta.indexOfValue("platform");
            os_categoryIdx = data.inputRowMeta.indexOfValue("os_category");
            osIdx = data.inputRowMeta.indexOfValue("os");
        }


	    String filename = String.format("%s/anonymized/%s/%s/%02d-run%s.log.lzo", new Object[] {
			getParameter("HDFS_LOCATION"),
            r[ site_nameIdx ],
            r[ utc_dateIdx ],
            r[ utc_hourIdx ],
            r[ runtimeIdx ]
	    });
        BufferedWriter writer = getWriter(filename);


        StringBuilder line = new StringBuilder();

		Boolean notBlacklisted = (Boolean) r[ not_in_blacklistIdx ];

        line
            .append(r[ common_pathIdx ]).append('\t')
            .append(r[ short_filenameIdx ]).append('\t')
            .append(r[ linenumIdx ]).append('\t')
            .append(r[ utc_timestampIdx ]).append('\t')
            .append(r[ client_timestampIdx ]).append('\t')
            .append(r[ country_codeIdx ]).append('\t')
            .append(r[ geohashIdx ]).append('\t')
            .append(r[ domainIdx ]).append('\t')
            .append(r[ orgIdx ]).append('\t')
            .append(r[ ispIdx ]).append('\t')
            .append(r[ request_methodIdx ]).append('\t')
            .append(r[ request_uriIdx ]).append('\t')
            .append(r[ request_versionIdx ]).append('\t')
            .append(r[ response_codeIdx ]).append('\t')
            .append(r[ response_sizeIdx ]).append('\t')
            .append(r[ referrerIdx ]).append('\t')
            .append(r[ browser_categoryIdx ]).append('\t')
            .append(r[ browser_nameIdx ]).append('\t')
            .append(r[ browser_versionIdx ]).append('\t')
            .append(r[ user_agent_localeIdx ]).append('\t')
            .append(r[ platformIdx ]).append('\t')
            .append(r[ os_categoryIdx ]).append('\t')
            .append(r[ osIdx ]).append('\t')
			.append( notBlacklisted ? "" : BLACKLIST_FLAG  )
			.append('\n');

        writer.write(line.toString());
		incrementLinesOutput();
    } catch (IOException e) {
        logError("IOException during write",e);
        setErrors(1);
        stopAll();
		setOutputDone();
		return false;
    }

	return true;
}

public void dispose(StepMetaInterface smi, StepDataInterface sdi)
{
	Iterator it = writers.entrySet().iterator();
	while (it.hasNext()) {
		Map.Entry entry = (Map.Entry)it.next();
		String filename = (String)entry.getKey();
		BufferedWriter writer = (BufferedWriter)entry.getValue();

	    try {
			logBasic("Closing writer for "+filename);
        	writer.close();
	    } catch (IOException e) {
    	    logError("IOException during close",e);
        	setErrors(1);
	        stopAll();
    	}
	}
    parent.disposeImpl(smi, sdi);
}

private BufferedWriter getWriter(String filename) throws KettleException, IOException {

	BufferedWriter writer = (BufferedWriter)writers.get(filename);
	if (writer == null) {
		FileObject fo = KettleVFS.getFileObject(filename, getTransMeta());
		fo.getParent().createFolder();
		OutputStream foOS = KettleVFS.getOutputStream(fo, false);
	    CompressionOutputStream compOS = lzoCodec.createOutputStream(foOS);
		writer = new BufferedWriter(new OutputStreamWriter(compOS));
		writers.put(filename, writer);
	}
    return writer;
}
]]></class_source>
        </definition>
    </definitions>
    <fields>
    </fields><clear_result_fields>Y</clear_result_fields>
<info_steps></info_steps><target_steps></target_steps><usage_parameters><usage_parameter><parameter_tag>HDFS_LOCATION</parameter_tag>
<parameter_value>${HDFS_LOCATION}</parameter_value>
<parameter_description/>
</usage_parameter></usage_parameters>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>833</xloc>
      <yloc>396</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Write Anonymized (No lzo&#47;hadoop)</name>
    <type>UserDefinedJavaClass</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>

    <definitions>
        <definition>
        <class_type>TRANSFORM_CLASS</class_type>

        <class_name>Processor</class_name>

        <class_source><![CDATA[import java.util.*;
import java.io.IOException;
import java.io.BufferedWriter;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import org.apache.commons.vfs.FileObject;
import org.pentaho.di.core.vfs.KettleVFS;

private static final String BLACKLIST_FLAG="\tblacklisted";

private HashMap writers = new HashMap();

int site_nameIdx, utc_dateIdx, utc_hourIdx, runtimeIdx, not_in_blacklistIdx,
    common_pathIdx, short_filenameIdx, linenumIdx, utc_timestampIdx, client_timestampIdx,
    country_codeIdx, geohashIdx, domainIdx, orgIdx, ispIdx,
    request_methodIdx, request_uriIdx, request_versionIdx, response_codeIdx, response_sizeIdx,
    referrerIdx, browser_categoryIdx, browser_nameIdx, browser_versionIdx, user_agent_localeIdx,
    platformIdx, os_categoryIdx, osIdx;

public boolean init(StepMetaInterface stepMetaInterface, StepDataInterface stepDataInterface)
{
	data.inputRowMeta.clear();
//	data.inputRowMeta = null;
    return parent.initImpl(stepMetaInterface, stepDataInterface);
}

public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException
{
	Object[] r = getRow();
	if (r == null) {
		setOutputDone();
		return false;
	}

    try {
        if (first)
        {
            first = false;
			data.inputRowMeta = getInputRowMeta();

// TODO PDI-4981
            site_nameIdx = data.inputRowMeta.indexOfValue("site_name");
            utc_dateIdx = data.inputRowMeta.indexOfValue("utc_date");
            utc_hourIdx = data.inputRowMeta.indexOfValue("utc_hour");
            runtimeIdx = data.inputRowMeta.indexOfValue("runtime");
            not_in_blacklistIdx = data.inputRowMeta.indexOfValue("not_in_blacklist");
            common_pathIdx = data.inputRowMeta.indexOfValue("common_path");
            short_filenameIdx = data.inputRowMeta.indexOfValue("short_filename");
            linenumIdx = data.inputRowMeta.indexOfValue("linenum");
            utc_timestampIdx = data.inputRowMeta.indexOfValue("utc_timestamp");
            client_timestampIdx = data.inputRowMeta.indexOfValue("client_timestamp");
            country_codeIdx = data.inputRowMeta.indexOfValue("country_code");
            geohashIdx = data.inputRowMeta.indexOfValue("geohash");
            domainIdx = data.inputRowMeta.indexOfValue("domain");
            orgIdx = data.inputRowMeta.indexOfValue("org");
            ispIdx = data.inputRowMeta.indexOfValue("isp");
            request_methodIdx = data.inputRowMeta.indexOfValue("request_method");
            request_uriIdx = data.inputRowMeta.indexOfValue("request_uri");
            request_versionIdx = data.inputRowMeta.indexOfValue("request_version");
            response_codeIdx = data.inputRowMeta.indexOfValue("response_code");
            response_sizeIdx = data.inputRowMeta.indexOfValue("response_size");
            referrerIdx = data.inputRowMeta.indexOfValue("referrer");
            browser_categoryIdx = data.inputRowMeta.indexOfValue("browser_category");
            browser_nameIdx = data.inputRowMeta.indexOfValue("browser_name");
            browser_versionIdx = data.inputRowMeta.indexOfValue("browser_version");
            user_agent_localeIdx = data.inputRowMeta.indexOfValue("user_agent_locale");
            platformIdx = data.inputRowMeta.indexOfValue("platform");
            os_categoryIdx = data.inputRowMeta.indexOfValue("os_category");
            osIdx = data.inputRowMeta.indexOfValue("os");
        }

	    String filename = String.format("%s/anonymized/%s/%s/%02d-run%s.log", new Object[] {
			getParameter("HDFS_LOCATION"),
            r[ site_nameIdx ],
            r[ utc_dateIdx ],
            r[ utc_hourIdx ],
            r[ runtimeIdx ]
	    });
        BufferedWriter writer = getWriter(filename);

        StringBuilder line = new StringBuilder();

		Boolean notBlacklisted = (Boolean) r[ not_in_blacklistIdx ];

        line
            .append(r[ common_pathIdx ]).append('\t')
            .append(r[ short_filenameIdx ]).append('\t')
            .append(r[ linenumIdx ]).append('\t')
            .append(r[ utc_timestampIdx ]).append('\t')
            .append(r[ client_timestampIdx ]).append('\t')
            .append(r[ country_codeIdx ]).append('\t')
            .append(r[ geohashIdx ]).append('\t')
            .append(r[ domainIdx ]).append('\t')
            .append(r[ orgIdx ]).append('\t')
            .append(r[ ispIdx ]).append('\t')
            .append(r[ request_methodIdx ]).append('\t')
            .append(r[ request_uriIdx ]).append('\t')
            .append(r[ request_versionIdx ]).append('\t')
            .append(r[ response_codeIdx ]).append('\t')
            .append(r[ response_sizeIdx ]).append('\t')
            .append(r[ referrerIdx ]).append('\t')
            .append(r[ browser_categoryIdx ]).append('\t')
            .append(r[ browser_nameIdx ]).append('\t')
            .append(r[ browser_versionIdx ]).append('\t')
            .append(r[ user_agent_localeIdx ]).append('\t')
            .append(r[ platformIdx ]).append('\t')
            .append(r[ os_categoryIdx ]).append('\t')
            .append(r[ osIdx ]).append('\t')
			.append( notBlacklisted ? "" : BLACKLIST_FLAG  )
			.append('\n');

        writer.write(line.toString());
		incrementLinesOutput();
    } catch (IOException e) {
        logError("IOException during write",e);
        setErrors(1);
        stopAll();
		setOutputDone();
		return false;
    }

	return true;
}

public void dispose(StepMetaInterface smi, StepDataInterface sdi)
{
	Iterator it = writers.entrySet().iterator();
	while (it.hasNext()) {
		Map.Entry entry = (Map.Entry)it.next();
		String filename = (String)entry.getKey();
		BufferedWriter writer = (BufferedWriter)entry.getValue();

	    try {
			logBasic("Closing writer for "+filename);
        	writer.close();
	    } catch (IOException e) {
    	    logError("IOException during close",e);
        	setErrors(1);
	        stopAll();
    	}
	}
    parent.disposeImpl(smi, sdi);
}

private BufferedWriter getWriter(String filename) throws KettleException, IOException {

	BufferedWriter writer = (BufferedWriter)writers.get(filename);
	if (writer == null) {
		FileObject fo = KettleVFS.getFileObject(filename, getTransMeta());
		fo.getParent().createFolder();
		OutputStream foOS = KettleVFS.getOutputStream(fo, false);
		writer = new BufferedWriter(new OutputStreamWriter(foOS));
		writers.put(filename, writer);
	}
    return writer;
}
]]></class_source>
        </definition>
    </definitions>
    <fields>
    </fields><clear_result_fields>Y</clear_result_fields>
<info_steps></info_steps><target_steps></target_steps><usage_parameters><usage_parameter><parameter_tag>HDFS_LOCATION</parameter_tag>
<parameter_value>${HDFS_LOCATION}</parameter_value>
<parameter_description/>
</usage_parameter></usage_parameters>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>993</xloc>
      <yloc>180</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Write Non-Anonymized</name>
    <type>UserDefinedJavaClass</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>

    <definitions>
        <definition>
        <class_type>TRANSFORM_CLASS</class_type>

        <class_name>Processor</class_name>

        <class_source><![CDATA[import java.util.*;
import java.io.IOException;
import java.io.BufferedWriter;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import org.apache.commons.vfs.FileObject;
import org.pentaho.di.core.vfs.KettleVFS;

import org.apache.hadoop.conf.Configuration;
import com.hadoop.compression.lzo.LzopCodec;
import org.apache.hadoop.io.compress.CompressionOutputStream;

private LzopCodec lzoCodec;
private Configuration config;

private HashMap writers = new HashMap();

int site_nameIdx, utc_dateIdx, utc_hourIdx, runtimeIdx, common_pathIdx, short_filenameIdx, linenumIdx, ipIdx, authIdx, identIdx, user_agentIdx, cookiesIdx;

public boolean init(StepMetaInterface stepMetaInterface, StepDataInterface stepDataInterface)
{
	config = new Configuration();
	config.set("fs.default.name", getParameter("HDFS_LOCATION"));
    lzoCodec = new LzopCodec();
	lzoCodec.setConf(config);
	data.inputRowMeta.clear();
	data.inputRowMeta = null;
    return parent.initImpl(stepMetaInterface, stepDataInterface);
}

public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException
{
	Object[] r = getRow();
	if (r == null) {
		setOutputDone();
		return false;
	}

    try {
        if (first)
        {
            first = false;
			data.inputRowMeta = getInputRowMeta();

// TODO PDI 4981
            site_nameIdx = data.inputRowMeta.indexOfValue("site_name");
            utc_dateIdx = data.inputRowMeta.indexOfValue("utc_date");
            utc_hourIdx = data.inputRowMeta.indexOfValue("utc_hour");
            runtimeIdx = data.inputRowMeta.indexOfValue("runtime");
            common_pathIdx = data.inputRowMeta.indexOfValue("common_path");
            short_filenameIdx = data.inputRowMeta.indexOfValue("short_filename");
            linenumIdx = data.inputRowMeta.indexOfValue("linenum");
            ipIdx = data.inputRowMeta.indexOfValue("ip");
            authIdx = data.inputRowMeta.indexOfValue("auth");
            identIdx = data.inputRowMeta.indexOfValue("ident");
            user_agentIdx = data.inputRowMeta.indexOfValue("user_agent");
            cookiesIdx = data.inputRowMeta.indexOfValue("cookies");
        }

	    String filename = String.format("%s/non-anonymized/%s/%s/%02d-run%s.log.lzo", new Object[] {
			getParameter("HDFS_LOCATION"),
            r[site_nameIdx],
            r[utc_dateIdx],
            r[utc_hourIdx],
            r[runtimeIdx]
	    });
        BufferedWriter writer = getWriter(filename);

        StringBuilder line = new StringBuilder();
        line
            .append( r[common_pathIdx] ).append('\t')
            .append( r[short_filenameIdx] ).append('\t')
            .append( r[linenumIdx] ).append('\t')
            .append( r[ipIdx] ).append('\t')
            .append( r[authIdx] ).append('\t')
            .append( r[identIdx] ).append('\t')
            .append( r[user_agentIdx] ).append('\t')
            .append( r[cookiesIdx] )
			.append('\n');

        writer.write(line.toString());
		incrementLinesOutput();
    } catch (IOException e) {
        logError("IOException during write",e);
        setErrors(1);
        stopAll();
		setOutputDone();
		return false;
    }

	return true;
}

public void dispose(StepMetaInterface smi, StepDataInterface sdi)
{
	Iterator it = writers.entrySet().iterator();
	while (it.hasNext()) {
		Map.Entry entry = (Map.Entry)it.next();
		String filename = (String)entry.getKey();
		BufferedWriter writer = (BufferedWriter)entry.getValue();

	    try {
			logBasic("Closing writer for "+filename);
        	writer.close();
	    } catch (IOException e) {
    	    logError("IOException during close",e);
        	setErrors(1);
	        stopAll();
    	}
	}
    parent.disposeImpl(smi, sdi);
}

private BufferedWriter getWriter(String filename) throws KettleException, IOException {

	BufferedWriter writer = (BufferedWriter)writers.get(filename);
	if (writer == null) {
		FileObject fo = KettleVFS.getFileObject(filename, getTransMeta());
		fo.getParent().createFolder();
		OutputStream foOS = KettleVFS.getOutputStream(fo, false);
	    CompressionOutputStream compOS = lzoCodec.createOutputStream(foOS);
		writer = new BufferedWriter(new OutputStreamWriter(compOS));
		writers.put(filename, writer);
	}
    return writer;
}

]]></class_source>
        </definition>
    </definitions>
    <fields>
    </fields><clear_result_fields>Y</clear_result_fields>
<info_steps></info_steps><target_steps></target_steps><usage_parameters><usage_parameter><parameter_tag>HDFS_LOCATION</parameter_tag>
<parameter_value>${HDFS_LOCATION}</parameter_value>
<parameter_description/>
</usage_parameter></usage_parameters>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>684</xloc>
      <yloc>401</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Write Non-Anonymized (No lzo&#47;hadoop)</name>
    <type>UserDefinedJavaClass</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>

    <definitions>
        <definition>
        <class_type>TRANSFORM_CLASS</class_type>

        <class_name>Processor</class_name>

        <class_source><![CDATA[import java.util.*;
import java.io.IOException;
import java.io.BufferedWriter;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import org.apache.commons.vfs.FileObject;
import org.pentaho.di.core.vfs.KettleVFS;

private HashMap writers = new HashMap();

int site_nameIdx, utc_dateIdx, utc_hourIdx, runtimeIdx, common_pathIdx, short_filenameIdx, linenumIdx, ipIdx, authIdx, identIdx, user_agentIdx, cookiesIdx;


public boolean init(StepMetaInterface stepMetaInterface, StepDataInterface stepDataInterface)
{
	data.inputRowMeta.clear();
//	data.inputRowMeta = null;
    return parent.initImpl(stepMetaInterface, stepDataInterface);
}

public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException
{
	Object[] r = getRow();
	if (r == null) {
		setOutputDone();
		return false;
	}

    try {
        if (first)
        {
            first = false;
			data.inputRowMeta = getInputRowMeta();

// TODO PDI 4981
            site_nameIdx = data.inputRowMeta.indexOfValue("site_name");
            utc_dateIdx = data.inputRowMeta.indexOfValue("utc_date");
            utc_hourIdx = data.inputRowMeta.indexOfValue("utc_hour");
            runtimeIdx = data.inputRowMeta.indexOfValue("runtime");
            common_pathIdx = data.inputRowMeta.indexOfValue("common_path");
            short_filenameIdx = data.inputRowMeta.indexOfValue("short_filename");
            linenumIdx = data.inputRowMeta.indexOfValue("linenum");
            ipIdx = data.inputRowMeta.indexOfValue("ip");
            authIdx = data.inputRowMeta.indexOfValue("auth");
            identIdx = data.inputRowMeta.indexOfValue("ident");
            user_agentIdx = data.inputRowMeta.indexOfValue("user_agent");
            cookiesIdx = data.inputRowMeta.indexOfValue("cookies");
        }

	    String filename = String.format("%s/non-anonymized/%s/%s/%02d-run%s.log", new Object[] {
			getParameter("HDFS_LOCATION"),
            r[site_nameIdx],
            r[utc_dateIdx],
            r[utc_hourIdx],
            r[runtimeIdx]
	    });
        BufferedWriter writer = getWriter(filename);

        StringBuilder line = new StringBuilder();
        line
            .append( r[common_pathIdx] ).append('\t')
            .append( r[short_filenameIdx] ).append('\t')
            .append( r[linenumIdx] ).append('\t')
            .append( r[ipIdx] ).append('\t')
            .append( r[authIdx] ).append('\t')
            .append( r[identIdx] ).append('\t')
            .append( r[user_agentIdx] ).append('\t')
            .append( r[cookiesIdx] )
			.append('\n');

        writer.write(line.toString());
		incrementLinesOutput();
    } catch (IOException e) {
        logError("IOException during write",e);
        setErrors(1);
        stopAll();
		setOutputDone();
		return false;
    }

	return true;
}

public void dispose(StepMetaInterface smi, StepDataInterface sdi)
{
	Iterator it = writers.entrySet().iterator();
	while (it.hasNext()) {
		Map.Entry entry = (Map.Entry)it.next();
		String filename = (String)entry.getKey();
		BufferedWriter writer = (BufferedWriter)entry.getValue();

	    try {
			logBasic("Closing writer for "+filename);
        	writer.close();
	    } catch (IOException e) {
    	    logError("IOException during close",e);
        	setErrors(1);
	        stopAll();
    	}
	}
    parent.disposeImpl(smi, sdi);
}

private BufferedWriter getWriter(String filename) throws KettleException, IOException {

	BufferedWriter writer = (BufferedWriter)writers.get(filename);
	if (writer == null) {
		FileObject fo = KettleVFS.getFileObject(filename, getTransMeta());
		fo.getParent().createFolder();
		OutputStream foOS = KettleVFS.getOutputStream(fo, false);
		writer = new BufferedWriter(new OutputStreamWriter(foOS));
		writers.put(filename, writer);
	}
    return writer;
}

]]></class_source>
        </definition>
    </definitions>
    <fields>
    </fields><clear_result_fields>Y</clear_result_fields>
<info_steps></info_steps><target_steps></target_steps><usage_parameters><usage_parameter><parameter_tag>HDFS_LOCATION</parameter_tag>
<parameter_value>${HDFS_LOCATION}</parameter_value>
<parameter_description/>
</usage_parameter></usage_parameters>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>996</xloc>
      <yloc>287</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step_error_handling>
  </step_error_handling>
   <slave-step-copy-partition-distribution>
</slave-step-copy-partition-distribution>
   <slave_transformation>N</slave_transformation>
</transformation>
